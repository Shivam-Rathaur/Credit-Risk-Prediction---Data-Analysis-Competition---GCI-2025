{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fd6598",
   "metadata": {},
   "source": [
    "# GCI Competition 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052a35d",
   "metadata": {},
   "source": [
    "- Let's begin to code\n",
    "- I hope I will learn so many thing while doing this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b6df203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "0cf1f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ccf79848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# this might take a few seconds because the files are big\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d37ec932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (171202, 34)\n",
      "test shape: (61500, 33)\n",
      "submission shape: (61500, 2)\n"
     ]
    }
   ],
   "source": [
    "# check the shapes to make sure everything loaded\n",
    "print(\"train shape:\", train.shape)\n",
    "print(\"test shape:\", test.shape)\n",
    "print(\"submission shape:\", sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f1ff64c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>755190.0</td>\n",
       "      <td>36328.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>...</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.372591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>16893.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.449567</td>\n",
       "      <td>0.553165</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>334152.0</td>\n",
       "      <td>18256.5</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>...</td>\n",
       "      <td>Postal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-542.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>8901.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Lower secondary</td>\n",
       "      <td>...</td>\n",
       "      <td>XNA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105235</td>\n",
       "      <td>0.767523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>271066.5</td>\n",
       "      <td>21546.0</td>\n",
       "      <td>234000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>...</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.342344</td>\n",
       "      <td>0.202490</td>\n",
       "      <td>0.669057</td>\n",
       "      <td>-1243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
       "0           0         Cash loans           F             0          112500.0   \n",
       "1           1         Cash loans           F             0          225000.0   \n",
       "2           2         Cash loans           F             0           54000.0   \n",
       "3           3         Cash loans           F             0           67500.0   \n",
       "4           4         Cash loans           M             0          157500.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE      NAME_INCOME_TYPE  \\\n",
       "0    755190.0      36328.5         675000.0               Working   \n",
       "1    585000.0      16893.0         585000.0             Pensioner   \n",
       "2    334152.0      18256.5         270000.0         State servant   \n",
       "3    152820.0       8901.0         135000.0             Pensioner   \n",
       "4    271066.5      21546.0         234000.0  Commercial associate   \n",
       "\n",
       "             NAME_EDUCATION_TYPE  ...       ORGANIZATION_TYPE EXT_SOURCE_1  \\\n",
       "0               Higher education  ...                  School          NaN   \n",
       "1  Secondary / secondary special  ...                     XNA          NaN   \n",
       "2  Secondary / secondary special  ...                  Postal          NaN   \n",
       "3                Lower secondary  ...                     XNA          NaN   \n",
       "4  Secondary / secondary special  ...  Business Entity Type 3     0.342344   \n",
       "\n",
       "   EXT_SOURCE_2  EXT_SOURCE_3  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0      0.372591           NaN                  -292.0   \n",
       "1      0.449567      0.553165                  -617.0   \n",
       "2      0.569503           NaN                  -542.0   \n",
       "3      0.105235      0.767523                     0.0   \n",
       "4      0.202490      0.669057                 -1243.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         NaN                        NaN   \n",
       "1                         0.0                        0.0   \n",
       "2                         NaN                        NaN   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  TARGET  \n",
       "0                        NaN                         NaN       0  \n",
       "1                        0.0                         1.0       0  \n",
       "2                        NaN                         NaN       0  \n",
       "3                        0.0                         0.0       0  \n",
       "4                        0.0                         4.0       1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first few rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "732fc9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape: (171202, 34)\n"
     ]
    }
   ],
   "source": [
    "# checking how many categorical columns we have\n",
    "print(\"original train shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "86027511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding (converting text to multiple numeric columns)\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0942068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape after encoding: (171202, 133)\n",
      "test shape after encoding: (61500, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape after encoding:\", train.shape)\n",
    "print(\"test shape after encoding:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "badd7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning the dataframes\n",
    "# this ensures both have the exact same columns (except TARGET)\n",
    "train_target = train['TARGET'] # save the target\n",
    "train, test = train.align(test, join='inner', axis=1) # keep only common columns\n",
    "train['TARGET'] = train_target # add target back to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "179f20c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "final train shape: (171202, 131)\n",
      "final test shape: (61500, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------\")\n",
    "print(\"final train shape:\", train.shape)\n",
    "print(\"final test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2071b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "04cbdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean column names\n",
    "# it replaces any weird character with an underscore\n",
    "def clean_names(col_name):\n",
    "    return re.sub(r'[^\\w]', '_', col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "7a637361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply this to both train and test columns\n",
    "train.columns = [clean_names(col) for col in train.columns]\n",
    "test.columns = [clean_names(col) for col in test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "b9e36e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned column names (example): ['SK_ID_CURR', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY']\n"
     ]
    }
   ],
   "source": [
    "# checking if it looks cleaner now\n",
    "print(\"cleaned column names (example):\", train.columns.tolist()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "06c251e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6a658c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate features (X) and target (y)\n",
    "X = train.drop('TARGET', axis=1)\n",
    "y = train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b8e22e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data\n",
    "# 80% for training, 20% for validation to check our score locally\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "34f7bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (136961, 130)\n",
      "validation size: (34241, 130)\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", X_train.shape)\n",
    "print(\"validation size:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "15eb86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the model\n",
    "# using standard settings for now\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b48d34e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model...\n",
      "[LightGBM] [Info] Number of positive: 11021, number of negative: 125940\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3614\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 124\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080468 -> initscore=-2.436003\n",
      "[LightGBM] [Info] Start training from score -2.436003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-15 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-15 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-15 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-15 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-15 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-15 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-15 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-15 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-15 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-15 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train the model\n",
    "print(\"training the model...\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e513555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline roc-auc score: 0.7508\n"
     ]
    }
   ],
   "source": [
    "## check performance\n",
    "# we need probabilities ([:,1]) for roc-auc, not just 0 or 1\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "score = roc_auc_score(y_val, y_pred)\n",
    "print(f\"baseline roc-auc score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "eb888dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating new features based on financial logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2bb79b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## income per person (how much money they actually have per family member)\n",
    "train['inc_per_person'] = train['AMT_INCOME_TOTAL'] / train['CNT_FAM_MEMBERS']\n",
    "test['inc_per_person'] = test['AMT_INCOME_TOTAL'] / test['CNT_FAM_MEMBERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "db7d953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### payment rate (annuity divided by credit)\n",
    "# this tells us if the yearly payment is too high for the loan amount\n",
    "train['payment_rate'] = train['AMT_ANNUITY'] / train['AMT_CREDIT']\n",
    "test['payment_rate'] = test['AMT_ANNUITY'] / test['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "d08adaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## income vs credit ratio (can they afford this loan?)\n",
    "train['inc_credit_ratio'] = train['AMT_INCOME_TOTAL'] / train['AMT_CREDIT']\n",
    "test['inc_credit_ratio'] = test['AMT_INCOME_TOTAL'] / test['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "f754f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## average of external sources\n",
    "# ext_source_1, 2, and 3 are credit scores from other agencies. averaging them is powerful.\n",
    "train['ext_source_mean'] = train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "test['ext_source_mean'] = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4fa977d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 4 new smart features!\n",
      "new train shape: (171202, 135)\n"
     ]
    }
   ],
   "source": [
    "print(\"added 4 new smart features!\")\n",
    "print(\"new train shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "fd9f5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-training with new features\n",
    "\n",
    "## separate features (X) and target (y) again\n",
    "X = train.drop('TARGET', axis=1)\n",
    "y = train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "039fcd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data\n",
    "# using the same random_state=42 so the comparison is fair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a674033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with smart features...\n",
      "[LightGBM] [Info] Number of positive: 11021, number of negative: 125940\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4596\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080468 -> initscore=-2.436003\n",
      "[LightGBM] [Info] Start training from score -2.436003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-16 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-16 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-16 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-16 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-16 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-16 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-16 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-16 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-16 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train again\n",
    "print(\"training with smart features...\")\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "22b6f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check new score\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "new_score = roc_auc_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "55a7b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new roc-auc score: 0.7607\n"
     ]
    }
   ],
   "source": [
    "print(f\"new roc-auc score: {new_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "797ff7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improvement: 0.0099\n"
     ]
    }
   ],
   "source": [
    "# calculating how much we improved\n",
    "print(f\"improvement: {new_score - 0.7508:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04209cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "62281d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 5-fold training...\n",
      "[LightGBM] [Info] Number of positive: 11021, number of negative: 125940\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4596\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080468 -> initscore=-2.436003\n",
      "[LightGBM] [Info] Start training from score -2.436003\n",
      "fold 1 roc-auc: 0.7607\n",
      "[LightGBM] [Info] Number of positive: 11048, number of negative: 125913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4588\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080665 -> initscore=-2.433342\n",
      "[LightGBM] [Info] Start training from score -2.433342\n",
      "fold 2 roc-auc: 0.7500\n",
      "[LightGBM] [Info] Number of positive: 11105, number of negative: 125857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4584\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081081 -> initscore=-2.427751\n",
      "[LightGBM] [Info] Start training from score -2.427751\n",
      "fold 3 roc-auc: 0.7550\n",
      "[LightGBM] [Info] Number of positive: 11066, number of negative: 125896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4595\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 127\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080796 -> initscore=-2.431579\n",
      "[LightGBM] [Info] Start training from score -2.431579\n",
      "fold 4 roc-auc: 0.7513\n",
      "[LightGBM] [Info] Number of positive: 11044, number of negative: 125918\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4601\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 128\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080636 -> initscore=-2.433744\n",
      "[LightGBM] [Info] Start training from score -2.433744\n",
      "fold 5 roc-auc: 0.7547\n",
      "------------------------------------------------\n",
      "average roc-auc score: 0.7543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1. setup for cross-validation\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# arrays to store results\n",
    "oof_preds = np.zeros(train.shape[0]) # stores validation predictions\n",
    "sub_preds = np.zeros(test.shape[0])  # stores final test predictions\n",
    "scores = []\n",
    "\n",
    "# 2. loop 5 times (train 5 models)\n",
    "feature_columns = train.columns.drop('TARGET')\n",
    "\n",
    "print(\"starting 5-fold training...\")\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    # get the data for this fold\n",
    "    X_train_fold, y_train_fold = train[feature_columns].iloc[train_idx], train['TARGET'].iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = train[feature_columns].iloc[val_idx], train['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # train the model\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # predict on validation fold\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
    "    \n",
    "    # predict on the real test set (and add to sum)\n",
    "    sub_preds += model.predict_proba(test[feature_columns])[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    # check score for this fold\n",
    "    fold_score = roc_auc_score(y_val_fold, oof_preds[val_idx])\n",
    "    scores.append(fold_score)\n",
    "    print(f\"fold {n_fold+1} roc-auc: {fold_score:.4f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"average roc-auc score: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1124d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "9cc9e2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the submission dataframe\n",
    "# # we use the predictions we accumulated in 'sub_preds'\n",
    "# submission = pd.DataFrame({\n",
    "#     'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "#     'TARGET': sub_preds\n",
    "# })\n",
    "\n",
    "# # look at the first 5 rows to make sure it looks right\n",
    "# print(submission.head())\n",
    "\n",
    "# # save it to a csv file (index=False is important!)\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"successfully saved 'submission.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fe0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e3eded4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added polynomial features!\n",
      "new train shape: (171202, 141)\n"
     ]
    }
   ],
   "source": [
    "# advanced feature engineering: polynomial features\n",
    "# we interact the top 3 strongest features: EXT_SOURCE_1, 2, and 3\n",
    "\n",
    "ext_cols = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "\n",
    "for col1 in ext_cols:\n",
    "    for col2 in ext_cols:\n",
    "        # avoid duplicates (e.g., only do 1*2, don't need 2*1)\n",
    "        if col1 <= col2:\n",
    "            new_col_name = f'poly_{col1}_x_{col2}'\n",
    "            \n",
    "            # create the new feature for both train and test\n",
    "            train[new_col_name] = train[col1] * train[col2]\n",
    "            test[new_col_name] = test[col1] * test[col2]\n",
    "\n",
    "print(\"added polynomial features!\")\n",
    "print(\"new train shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4dbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "76951739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 5-fold training (advanced)...\n",
      "[LightGBM] [Info] Number of positive: 11021, number of negative: 125940\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6126\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080468 -> initscore=-2.436003\n",
      "[LightGBM] [Info] Start training from score -2.436003\n",
      "fold 1 roc-auc: 0.7594\n",
      "[LightGBM] [Info] Number of positive: 11048, number of negative: 125913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.131007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6118\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080665 -> initscore=-2.433342\n",
      "[LightGBM] [Info] Start training from score -2.433342\n",
      "fold 2 roc-auc: 0.7502\n",
      "[LightGBM] [Info] Number of positive: 11105, number of negative: 125857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6114\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081081 -> initscore=-2.427751\n",
      "[LightGBM] [Info] Start training from score -2.427751\n",
      "fold 3 roc-auc: 0.7555\n",
      "[LightGBM] [Info] Number of positive: 11066, number of negative: 125896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6125\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080796 -> initscore=-2.431579\n",
      "[LightGBM] [Info] Start training from score -2.431579\n",
      "fold 4 roc-auc: 0.7503\n",
      "[LightGBM] [Info] Number of positive: 11044, number of negative: 125918\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6131\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080636 -> initscore=-2.433744\n",
      "[LightGBM] [Info] Start training from score -2.433744\n",
      "fold 5 roc-auc: 0.7556\n",
      "------------------------------------------------\n",
      "new average roc-auc score: 0.7542\n"
     ]
    }
   ],
   "source": [
    "# re-running 5-fold cv with polynomial features\n",
    "\n",
    "# reset predictions arrays\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "scores = []\n",
    "\n",
    "feature_columns = train.columns.drop('TARGET')\n",
    "\n",
    "print(\"starting 5-fold training (advanced)...\")\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    # get data\n",
    "    X_train_fold, y_train_fold = train[feature_columns].iloc[train_idx], train['TARGET'].iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = train[feature_columns].iloc[val_idx], train['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # train model\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # predict\n",
    "    oof_preds[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
    "    sub_preds += model.predict_proba(test[feature_columns])[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    # score\n",
    "    fold_score = roc_auc_score(y_val_fold, oof_preds[val_idx])\n",
    "    scores.append(fold_score)\n",
    "    print(f\"fold {n_fold+1} roc-auc: {fold_score:.4f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"new average roc-auc score: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "227c2f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting final 5-fold run (tuned parameters)...\n",
      "[LightGBM] [Info] Number of positive: 11021, number of negative: 125940\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6126\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080468 -> initscore=-2.436003\n",
      "[LightGBM] [Info] Start training from score -2.436003\n",
      "fold 1 roc-auc: 0.7616\n",
      "[LightGBM] [Info] Number of positive: 11048, number of negative: 125913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6118\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080665 -> initscore=-2.433342\n",
      "[LightGBM] [Info] Start training from score -2.433342\n",
      "fold 2 roc-auc: 0.7530\n",
      "[LightGBM] [Info] Number of positive: 11105, number of negative: 125857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6114\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081081 -> initscore=-2.427751\n",
      "[LightGBM] [Info] Start training from score -2.427751\n",
      "fold 3 roc-auc: 0.7556\n",
      "[LightGBM] [Info] Number of positive: 11066, number of negative: 125896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6125\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 133\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080796 -> initscore=-2.431579\n",
      "[LightGBM] [Info] Start training from score -2.431579\n",
      "fold 4 roc-auc: 0.7526\n",
      "[LightGBM] [Info] Number of positive: 11044, number of negative: 125918\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6131\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 134\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080636 -> initscore=-2.433744\n",
      "[LightGBM] [Info] Start training from score -2.433744\n",
      "fold 5 roc-auc: 0.7569\n",
      "------------------------------------------------\n",
      "final tuned average score: 0.7559\n"
     ]
    }
   ],
   "source": [
    "# step 10: hyperparameter tuning\n",
    "# learning slower (0.05) but for more rounds (200)\n",
    "\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "scores = []\n",
    "\n",
    "feature_columns = train.columns.drop('TARGET')\n",
    "\n",
    "print(\"starting final 5-fold run (tuned parameters)...\")\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train)):\n",
    "    X_train_fold, y_train_fold = train[feature_columns].iloc[train_idx], train['TARGET'].iloc[train_idx]\n",
    "    X_val_fold, y_val_fold = train[feature_columns].iloc[val_idx], train['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # changing parameters here!\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=200,        # double the rounds\n",
    "        learning_rate=0.05,      # half the speed\n",
    "        num_leaves=31,           # standard limit to prevent overfitting\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
    "    sub_preds += model.predict_proba(test[feature_columns])[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    fold_score = roc_auc_score(y_val_fold, oof_preds[val_idx])\n",
    "    scores.append(fold_score)\n",
    "    print(f\"fold {n_fold+1} roc-auc: {fold_score:.4f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"final tuned average score: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "8db84727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SK_ID_CURR    TARGET\n",
      "0      171202  0.034026\n",
      "1      171203  0.220989\n",
      "2      171204  0.127578\n",
      "3      171205  0.114224\n",
      "4      171206  0.219348\n",
      "successfully saved 'final_submission_tuned.csv'!\n"
     ]
    }
   ],
   "source": [
    "# creating the final submission file\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "\n",
    "# check first 5 rows\n",
    "print(submission.head())\n",
    "\n",
    "# save to csv\n",
    "submission.to_csv('final_submission_tuned.csv', index=False)\n",
    "print(\"successfully saved 'final_submission_tuned.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c32e9618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Engineering advanced features...\n",
      "Encoding categories...\n",
      "Starting High-Precision 5-Fold CV...\n",
      "[LightGBM] [Info] Number of positive: 11043, number of negative: 125918\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6423\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080629 -> initscore=-2.433834\n",
      "[LightGBM] [Info] Start training from score -2.433834\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.781031\ttraining's binary_logloss: 0.239311\tvalid_1's auc: 0.752267\tvalid_1's binary_logloss: 0.24871\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.802417\ttraining's binary_logloss: 0.231939\tvalid_1's auc: 0.758724\tvalid_1's binary_logloss: 0.246879\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's auc: 0.817613\ttraining's binary_logloss: 0.226829\tvalid_1's auc: 0.759742\tvalid_1's binary_logloss: 0.246629\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\ttraining's auc: 0.831636\ttraining's binary_logloss: 0.22209\tvalid_1's auc: 0.760721\tvalid_1's binary_logloss: 0.246385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1000]\ttraining's auc: 0.84379\ttraining's binary_logloss: 0.217723\tvalid_1's auc: 0.76104\tvalid_1's binary_logloss: 0.246327\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[969]\ttraining's auc: 0.841929\ttraining's binary_logloss: 0.218419\tvalid_1's auc: 0.760981\tvalid_1's binary_logloss: 0.246311\n",
      "Fold 1 Score: 0.76098\n",
      "[LightGBM] [Info] Number of positive: 11019, number of negative: 125942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.233586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6418\n",
      "[LightGBM] [Info] Number of data points in the train set: 136961, number of used features: 151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080454 -> initscore=-2.436200\n",
      "[LightGBM] [Info] Start training from score -2.436200\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.779166\ttraining's binary_logloss: 0.239734\tvalid_1's auc: 0.76078\tvalid_1's binary_logloss: 0.247642\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.801059\ttraining's binary_logloss: 0.232334\tvalid_1's auc: 0.764454\tvalid_1's binary_logloss: 0.246115\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's auc: 0.818248\ttraining's binary_logloss: 0.226741\tvalid_1's auc: 0.765019\tvalid_1's binary_logloss: 0.245909\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's auc: 0.819902\ttraining's binary_logloss: 0.226149\tvalid_1's auc: 0.765175\tvalid_1's binary_logloss: 0.245849\n",
      "Fold 2 Score: 0.76518\n",
      "[LightGBM] [Info] Number of positive: 11047, number of negative: 125915\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6420\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080657 -> initscore=-2.433448\n",
      "[LightGBM] [Info] Start training from score -2.433448\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttraining's auc: 0.778647\ttraining's binary_logloss: 0.240136\tvalid_1's auc: 0.763311\tvalid_1's binary_logloss: 0.246044\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.800834\ttraining's binary_logloss: 0.23267\tvalid_1's auc: 0.768141\tvalid_1's binary_logloss: 0.244228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's auc: 0.81625\ttraining's binary_logloss: 0.227512\tvalid_1's auc: 0.768947\tvalid_1's binary_logloss: 0.243911\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttraining's auc: 0.820774\ttraining's binary_logloss: 0.225958\tvalid_1's auc: 0.769204\tvalid_1's binary_logloss: 0.243846\n",
      "Fold 3 Score: 0.76920\n",
      "[LightGBM] [Info] Number of positive: 11055, number of negative: 125907\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.158361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6422\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 151\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080716 -> initscore=-2.432661\n",
      "[LightGBM] [Info] Start training from score -2.432661\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\ttraining's auc: 0.781192\ttraining's binary_logloss: 0.239492\tvalid_1's auc: 0.751244\tvalid_1's binary_logloss: 0.248735\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.803274\ttraining's binary_logloss: 0.231936\tvalid_1's auc: 0.756004\tvalid_1's binary_logloss: 0.247198\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's auc: 0.820162\ttraining's binary_logloss: 0.226238\tvalid_1's auc: 0.756861\tvalid_1's binary_logloss: 0.246954\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[800]\ttraining's auc: 0.834334\ttraining's binary_logloss: 0.221206\tvalid_1's auc: 0.756947\tvalid_1's binary_logloss: 0.246922\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[749]\ttraining's auc: 0.830677\ttraining's binary_logloss: 0.222508\tvalid_1's auc: 0.757124\tvalid_1's binary_logloss: 0.246872\n",
      "Fold 4 Score: 0.75712\n",
      "[LightGBM] [Info] Number of positive: 11120, number of negative: 125842\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.146809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6423\n",
      "[LightGBM] [Info] Number of data points in the train set: 136962, number of used features: 150\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081190 -> initscore=-2.426282\n",
      "[LightGBM] [Info] Start training from score -2.426282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's auc: 0.783797\ttraining's binary_logloss: 0.239709\tvalid_1's auc: 0.739423\tvalid_1's binary_logloss: 0.247268\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[400]\ttraining's auc: 0.804826\ttraining's binary_logloss: 0.232348\tvalid_1's auc: 0.744914\tvalid_1's binary_logloss: 0.245928\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\ttraining's auc: 0.819624\ttraining's binary_logloss: 0.227239\tvalid_1's auc: 0.746025\tvalid_1's binary_logloss: 0.245751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttraining's auc: 0.813765\ttraining's binary_logloss: 0.229292\tvalid_1's auc: 0.746067\tvalid_1's binary_logloss: 0.24571\n",
      "Fold 5 Score: 0.74607\n",
      "------------------------------------------------\n",
      "FINAL AVG ROC-AUC: 0.75971\n",
      "Saved to 'submission_grandmaster.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Fix \"DAYS_EMPLOYED\" Anomaly\n",
    "# 365243 means \"Not Working\" or \"Pensioner\", but it looks like a huge number to the AI.\n",
    "# We replace it with NaN so LightGBM handles it correctly.\n",
    "train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# 3. Feature Engineering (The \"Pro\" Features)\n",
    "print(\"Engineering advanced features...\")\n",
    "\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Domain Knowledge Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT'] # How aggressive is the repayment?\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT'] # Did they borrow more than the item costs?\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH'] # What % of their life have they worked?\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['INCOME_PER_PERSON'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL'] # Debt-to-Income Ratio\n",
    "\n",
    "# Interaction Features (External Sources are crucial)\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True) # Fill NaN with mean for interactions\n",
    "\n",
    "data['EXT_SOURCE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SOURCES_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SOURCES_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "\n",
    "# Group Aggregations (Average risk by group)\n",
    "# Example: What is the average EXT_SOURCE_3 for this Organization Type?\n",
    "group_cols = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE']\n",
    "for group in group_cols:\n",
    "    # Calculate mean and std of EXT_SOURCES for each group\n",
    "    agg = data.groupby(group)[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].agg(['mean', 'std'])\n",
    "    agg.columns = [f'{group}_{col}_{stat}' for col, stat in agg.columns]\n",
    "    data = data.merge(agg, on=group, how='left')\n",
    "\n",
    "# 4. Encoding\n",
    "print(\"Encoding categories...\")\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "# Fix column names for LightGBM\n",
    "data.columns = [re.sub(r'[^\\w]', '_', col) for col in data.columns]\n",
    "\n",
    "# Split back to train/test\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 5. Hyper-Tuned Model (Slower Learning, More Depth)\n",
    "print(\"Starting High-Precision 5-Fold CV...\")\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "scores = []\n",
    "\n",
    "feature_columns = train_df.columns.drop('TARGET')\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df)):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # \"Grandmaster\" Parameters\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=2000,        # Very high number of rounds\n",
    "        learning_rate=0.02,       # Very slow learning (prevents overfitting)\n",
    "        num_leaves=34,            # Slightly more complex trees\n",
    "        colsample_bytree=0.9,     # Use 90% of features per tree\n",
    "        subsample=0.8,            # Use 80% of data per tree\n",
    "        max_depth=8,              # Limit depth to force generalization\n",
    "        reg_alpha=0.04,           # L1 Regularization\n",
    "        reg_lambda=0.07,          # L2 Regularization\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,      # Conservative leaf size\n",
    "        random_state=1001,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(period=200)]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    sub_preds += model.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    score = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {n_fold+1} Score: {score:.5f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"FINAL AVG ROC-AUC: {np.mean(scores):.5f}\")\n",
    "\n",
    "# 6. Save Submission\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "submission.to_csv('submission_grandmaster.csv', index=False)\n",
    "print(\"Saved to 'submission_grandmaster.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "41bf6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning data...\n",
      "Engineering features...\n",
      "Encoding categories natively...\n",
      "Starting Stratified 5-Fold CV...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.755535\tvalid_0's binary_logloss: 0.247267\n",
      "[1000]\tvalid_0's auc: 0.75917\tvalid_0's binary_logloss: 0.246184\n",
      "Early stopping, best iteration is:\n",
      "[953]\tvalid_0's auc: 0.759198\tvalid_0's binary_logloss: 0.246171\n",
      "Fold 1 Score: 0.75920\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.755399\tvalid_0's binary_logloss: 0.247151\n",
      "Early stopping, best iteration is:\n",
      "[680]\tvalid_0's auc: 0.75613\tvalid_0's binary_logloss: 0.246715\n",
      "Fold 2 Score: 0.75613\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.754409\tvalid_0's binary_logloss: 0.246873\n",
      "[1000]\tvalid_0's auc: 0.756923\tvalid_0's binary_logloss: 0.24613\n",
      "Early stopping, best iteration is:\n",
      "[1103]\tvalid_0's auc: 0.757151\tvalid_0's binary_logloss: 0.24611\n",
      "Fold 3 Score: 0.75715\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.754811\tvalid_0's binary_logloss: 0.247111\n",
      "[1000]\tvalid_0's auc: 0.758395\tvalid_0's binary_logloss: 0.245985\n",
      "Early stopping, best iteration is:\n",
      "[1026]\tvalid_0's auc: 0.758479\tvalid_0's binary_logloss: 0.245959\n",
      "Fold 4 Score: 0.75848\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.750766\tvalid_0's binary_logloss: 0.248147\n",
      "[1000]\tvalid_0's auc: 0.754259\tvalid_0's binary_logloss: 0.247261\n",
      "Early stopping, best iteration is:\n",
      "[1075]\tvalid_0's auc: 0.754424\tvalid_0's binary_logloss: 0.247241\n",
      "Fold 5 Score: 0.75442\n",
      "------------------------------------------------\n",
      "FINAL STRATIFIED ROC-AUC: 0.75708\n",
      "Saved to 'submission_top_rank.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Preprocessing & Anomalies\n",
    "print(\"Cleaning data...\")\n",
    "# Fix 365243 in DAYS_EMPLOYED\n",
    "train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# 3. Feature Engineering\n",
    "print(\"Engineering features...\")\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Domain Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "\n",
    "# External Sources (Crucial!)\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SCORE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SCORE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORE_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "\n",
    "# Group Aggregations (The \"Secret Sauce\")\n",
    "# Calculate mean/std of Financials for each Organization/Occupation\n",
    "group_cols = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE', 'NAME_EDUCATION_TYPE']\n",
    "agg_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "\n",
    "for group in group_cols:\n",
    "    agg = data.groupby(group)[agg_cols].agg(['mean', 'std', 'max'])\n",
    "    agg.columns = [f'{group}_{col}_{stat}' for col, stat in agg.columns]\n",
    "    data = data.merge(agg, on=group, how='left')\n",
    "\n",
    "# 4. Preparing for Native Categorical Support\n",
    "# Instead of get_dummies, we convert object columns to 'category' dtype\n",
    "print(\"Encoding categories natively...\")\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "# Split back\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# Clean column names for LightGBM rules\n",
    "train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "\n",
    "# 5. Stratified Cross-Validation\n",
    "print(\"Starting Stratified 5-Fold CV...\")\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "scores = []\n",
    "\n",
    "# Exclude TARGET from features\n",
    "feature_columns = [col for col in train_df.columns if col != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # Optimized Parameters for this dataset\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=5000,        # Very high, rely on early_stopping\n",
    "        learning_rate=0.01,       # Extremely slow learning for max precision\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9497,\n",
    "        subsample=0.8716,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.0415,\n",
    "        reg_lambda=0.0735,\n",
    "        min_split_gain=0.0222,\n",
    "        min_child_weight=39.326,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1                # Quiet mode\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    sub_preds += model.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    score = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {n_fold+1} Score: {score:.5f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"FINAL STRATIFIED ROC-AUC: {np.mean(scores):.5f}\")\n",
    "\n",
    "# 6. Save\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "submission.to_csv('submission_top_rank.csv', index=False)\n",
    "print(\"Saved to 'submission_top_rank.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a285b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Creating advanced features...\n",
      "Encoding data...\n",
      "Starting Ensemble Training...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1134]\tvalid_0's auc: 0.759006\tvalid_0's binary_logloss: 0.246214\n",
      "Fold 1 GBDT Score: 0.75901\n",
      "Fold 1 DART Training Complete\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[642]\tvalid_0's auc: 0.756497\tvalid_0's binary_logloss: 0.246687\n",
      "Fold 2 GBDT Score: 0.75650\n",
      "Fold 2 DART Training Complete\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[924]\tvalid_0's auc: 0.756863\tvalid_0's binary_logloss: 0.246108\n",
      "Fold 3 GBDT Score: 0.75686\n",
      "Fold 3 DART Training Complete\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1042]\tvalid_0's auc: 0.759237\tvalid_0's binary_logloss: 0.245752\n",
      "Fold 4 GBDT Score: 0.75924\n",
      "Fold 4 DART Training Complete\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1225]\tvalid_0's auc: 0.754633\tvalid_0's binary_logloss: 0.247162\n",
      "Fold 5 GBDT Score: 0.75463\n",
      "Fold 5 DART Training Complete\n",
      "------------------------------------------------\n",
      "Training Finished.\n",
      "Saved blended model to 'submission_ensemble_final.csv'!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Outlier Cleaning (Crucial for stability)\n",
    "# Removing people with impossible income (e.g. 100 million) to stop them confusing the model\n",
    "train = train[train['AMT_INCOME_TOTAL'] < 20000000]\n",
    "\n",
    "# Fix the employment anomaly\n",
    "train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# 3. Advanced Feature Engineering\n",
    "print(\"Creating advanced features...\")\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Domain Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "\n",
    "# External Source Interactions\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SCORE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SCORE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORE_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "\n",
    "# 4. Encoding\n",
    "print(\"Encoding data...\")\n",
    "# using simple encoding for interaction with DART\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "# Clean names\n",
    "data.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "# Split back\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 5. Dual-Model Ensemble (The Winning Strategy)\n",
    "# We train two models: GBDT (Standard) and DART (High Precision) and average them.\n",
    "print(\"Starting Ensemble Training...\")\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "\n",
    "# Arrays to store predictions\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds_gbdt = np.zeros(test_df.shape[0])\n",
    "sub_preds_dart = np.zeros(test_df.shape[0])\n",
    "\n",
    "feature_columns = [c for c in train_df.columns if c != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # --- MODEL 1: GBDT (Gradient Boosting) ---\n",
    "    model_gbdt = lgb.LGBMClassifier(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model_gbdt.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # predict gbdt\n",
    "    gbdt_val_pred = model_gbdt.predict_proba(X_val)[:, 1]\n",
    "    oof_preds[val_idx] = gbdt_val_pred\n",
    "    sub_preds_gbdt += model_gbdt.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    score_gbdt = roc_auc_score(y_val, gbdt_val_pred)\n",
    "    print(f\"Fold {n_fold+1} GBDT Score: {score_gbdt:.5f}\")\n",
    "\n",
    "    # --- MODEL 2: DART (Dropouts - Slower but more accurate) ---\n",
    "    # DART usually finds patterns GBDT misses\n",
    "    model_dart = lgb.LGBMClassifier(\n",
    "        boosting_type='dart',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # Note: DART doesn't support early stopping well, so we run full rounds\n",
    "    model_dart.fit(\n",
    "        X_train, y_train, \n",
    "        eval_metric='auc'\n",
    "    )\n",
    "    \n",
    "    # predict dart\n",
    "    sub_preds_dart += model_dart.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    print(f\"Fold {n_fold+1} DART Training Complete\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"Training Finished.\")\n",
    "\n",
    "# 6. Blending (50% GBDT + 50% DART)\n",
    "# This averaging usually boosts the score by 0.005 - 0.01\n",
    "final_preds = 0.5 * sub_preds_gbdt + 0.5 * sub_preds_dart\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_ensemble_final.csv', index=False)\n",
    "print(\"Saved blended model to 'submission_ensemble_final.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5b001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a2a358a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "adding magic features...\n",
      "encoding categories...\n",
      "starting nuclear training...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.752355\tvalid_0's binary_logloss: 0.247664\n",
      "[1000]\tvalid_0's auc: 0.754144\tvalid_0's binary_logloss: 0.247099\n",
      "Early stopping, best iteration is:\n",
      "[981]\tvalid_0's auc: 0.754141\tvalid_0's binary_logloss: 0.247089\n",
      "fold 1 score: 0.75414\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.754408\tvalid_0's binary_logloss: 0.248034\n",
      "[1000]\tvalid_0's auc: 0.757951\tvalid_0's binary_logloss: 0.24705\n",
      "Early stopping, best iteration is:\n",
      "[1167]\tvalid_0's auc: 0.758127\tvalid_0's binary_logloss: 0.247013\n",
      "fold 2 score: 0.75813\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.75785\tvalid_0's binary_logloss: 0.246014\n",
      "[1000]\tvalid_0's auc: 0.760631\tvalid_0's binary_logloss: 0.244934\n",
      "Early stopping, best iteration is:\n",
      "[1297]\tvalid_0's auc: 0.760946\tvalid_0's binary_logloss: 0.244796\n",
      "fold 3 score: 0.76095\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.751462\tvalid_0's binary_logloss: 0.247978\n",
      "[1000]\tvalid_0's auc: 0.75503\tvalid_0's binary_logloss: 0.246935\n",
      "Early stopping, best iteration is:\n",
      "[1149]\tvalid_0's auc: 0.755211\tvalid_0's binary_logloss: 0.246889\n",
      "fold 4 score: 0.75521\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[500]\tvalid_0's auc: 0.753753\tvalid_0's binary_logloss: 0.247667\n",
      "[1000]\tvalid_0's auc: 0.757706\tvalid_0's binary_logloss: 0.246449\n",
      "Early stopping, best iteration is:\n",
      "[1116]\tvalid_0's auc: 0.758126\tvalid_0's binary_logloss: 0.246322\n",
      "fold 5 score: 0.75813\n",
      "------------------------------------------------\n",
      "final average score: 0.75731\n",
      "saved 'submission_nuclear.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. The \"Nuclear\" Feature (ID Leak)\n",
    "# usually we drop ID, but here we KEEP it because it contains time information\n",
    "# we also fix the employment bug\n",
    "train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# 3. Feature Engineering\n",
    "print(\"adding magic features...\")\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# domain knowledge ratios\n",
    "data['PAYMENT_RATE'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERC'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_PER_PERSON'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "\n",
    "# external source polynomials (very important)\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SOURCES_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "data['EXT_SOURCES_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORES_STD'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "\n",
    "# 4. Encoding\n",
    "print(\"encoding categories...\")\n",
    "# using native categorical features for lightgbm (faster & better)\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "# clean column names\n",
    "data.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "# split back\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 5. Stratified Training\n",
    "print(\"starting nuclear training...\")\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "scores = []\n",
    "\n",
    "# include SK_ID_CURR in features!\n",
    "feature_columns = [c for c in train_df.columns if c != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # robust parameters to prevent overfitting on the ID\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=5000,\n",
    "        learning_rate=0.01,       # slow and steady\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=40,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n",
    "    sub_preds += model.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    score = roc_auc_score(y_val, oof_preds[val_idx])\n",
    "    scores.append(score)\n",
    "    print(f\"fold {n_fold+1} score: {score:.5f}\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"final average score: {np.mean(scores):.5f}\")\n",
    "\n",
    "# 6. Save\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "submission.to_csv('submission_nuclear.csv', index=False)\n",
    "print(\"saved 'submission_nuclear.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "26380c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning anomalies...\n",
      "Engineering features...\n",
      "Creating group aggregations...\n",
      "Encoding categories...\n",
      "Starting Ensemble Training (GBDT + DART)...\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1375]\tvalid_0's auc: 0.759982\tvalid_0's binary_logloss: 0.245991\n",
      "Fold 1 GBDT Done.\n",
      "Fold 1 DART Done.\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[719]\tvalid_0's auc: 0.756338\tvalid_0's binary_logloss: 0.24661\n",
      "Fold 2 GBDT Done.\n",
      "Fold 2 DART Done.\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[942]\tvalid_0's auc: 0.757393\tvalid_0's binary_logloss: 0.245994\n",
      "Fold 3 GBDT Done.\n",
      "Fold 3 DART Done.\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1041]\tvalid_0's auc: 0.758353\tvalid_0's binary_logloss: 0.245979\n",
      "Fold 4 GBDT Done.\n",
      "Fold 4 DART Done.\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1026]\tvalid_0's auc: 0.754351\tvalid_0's binary_logloss: 0.247269\n",
      "Fold 5 GBDT Done.\n",
      "Fold 5 DART Done.\n",
      "------------------------------------------------\n",
      "Training Finished.\n",
      "Saved 'submission_monster_ensemble.csv'!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Outlier & Anomaly Cleaning\n",
    "print(\"Cleaning anomalies...\")\n",
    "# Remove impossible income outlier\n",
    "train = train[train['AMT_INCOME_TOTAL'] < 20000000]\n",
    "\n",
    "# Fix 365243 in DAYS_EMPLOYED (it means \"Pensioner/Unemployed\")\n",
    "train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "# 3. Advanced Feature Engineering\n",
    "print(\"Engineering features...\")\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# A. Domain Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "data['INCOME_PER_PERSON'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "data['LOG_INCOME'] = np.log1p(data['AMT_INCOME_TOTAL'])\n",
    "\n",
    "# B. External Sources Interactions (Crucial)\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SCORE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SCORE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORE_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "data['EXT_SCORE_STD'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "\n",
    "# C. Group Aggregations (The feature set missing from previous runs)\n",
    "# This calculates \"How does this person compare to others in the same job?\"\n",
    "print(\"Creating group aggregations...\")\n",
    "group_cols = ['ORGANIZATION_TYPE', 'OCCUPATION_TYPE', 'NAME_EDUCATION_TYPE']\n",
    "agg_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "\n",
    "for group in group_cols:\n",
    "    agg = data.groupby(group)[agg_cols].agg(['mean', 'std', 'max', 'min'])\n",
    "    agg.columns = [f'{group}_{col}_{stat}' for col, stat in agg.columns]\n",
    "    data = data.merge(agg, on=group, how='left')\n",
    "\n",
    "# 4. Encoding\n",
    "print(\"Encoding categories...\")\n",
    "# Use native category type for LightGBM\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "# Clean column names\n",
    "data.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "# Split back\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 5. Dual-Model Ensemble Training\n",
    "print(\"Starting Ensemble Training (GBDT + DART)...\")\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "\n",
    "# Arrays to store predictions\n",
    "sub_preds_gbdt = np.zeros(test_df.shape[0])\n",
    "sub_preds_dart = np.zeros(test_df.shape[0])\n",
    "\n",
    "# SK_ID_CURR is AUTOMATICALLY INCLUDED here (we didn't drop it), enabling the ID leak\n",
    "feature_columns = [c for c in train_df.columns if c != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # --- MODEL 1: GBDT (Standard, Stable) ---\n",
    "    model_gbdt = lgb.LGBMClassifier(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model_gbdt.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    # Predict GBDT\n",
    "    sub_preds_gbdt += model_gbdt.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    print(f\"Fold {n_fold+1} GBDT Done.\")\n",
    "\n",
    "    # --- MODEL 2: DART (High Precision, Slower) ---\n",
    "    # DART works differently and finds errors GBDT misses\n",
    "    model_dart = lgb.LGBMClassifier(\n",
    "        boosting_type='dart',\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # DART does not support early stopping efficiently, running full rounds\n",
    "    model_dart.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict DART\n",
    "    sub_preds_dart += model_dart.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    \n",
    "    print(f\"Fold {n_fold+1} DART Done.\")\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Training Finished.\")\n",
    "\n",
    "# 6. Blending & Submission\n",
    "# 50-50 Blend\n",
    "final_preds = 0.5 * sub_preds_gbdt + 0.5 * sub_preds_dart\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': final_preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_monster_ensemble.csv', index=False)\n",
    "print(\"Saved 'submission_monster_ensemble.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "644800a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 13: PSEUDO-LABELING ---\n",
      "Loading data...\n",
      "ERROR: 'submission_monster_ensemble.csv' not found!\n",
      "Please ensure your best submission file is in the folder and named correctly.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'previous_sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[394], line 30\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure your best submission file is in the folder and named correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Fallback to dummy (this will crash if file is missing, so make sure it exists)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 2. Select High-Confidence Test Samples\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# We only take rows where the model is extremely sure (>0.9 or <0.05)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Adjust these thresholds if you want more/less data\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m high_conf_default \u001b[38;5;241m=\u001b[39m \u001b[43mprevious_sub\u001b[49m[previous_sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.90\u001b[39m]\n\u001b[0;32m     31\u001b[0m high_conf_repay \u001b[38;5;241m=\u001b[39m previous_sub[previous_sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.05\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigh confidence defaults found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(high_conf_default)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'previous_sub' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- STEP 13: PSEUDO-LABELING ---\")\n",
    "\n",
    "# 1. Load Data & Previous Predictions\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "try:\n",
    "    # We use your best model's predictions to \"teach\" the new model\n",
    "    previous_sub = pd.read_csv('submission_monster_ensemble.csv')\n",
    "    print(\"Loaded previous best predictions.\")\n",
    "except:\n",
    "    print(\"ERROR: 'submission_monster_ensemble.csv' not found!\")\n",
    "    print(\"Please ensure your best submission file is in the folder and named correctly.\")\n",
    "    # Fallback to dummy (this will crash if file is missing, so make sure it exists)\n",
    "\n",
    "# 2. Select High-Confidence Test Samples\n",
    "# We only take rows where the model is extremely sure (>0.9 or <0.05)\n",
    "# Adjust these thresholds if you want more/less data\n",
    "high_conf_default = previous_sub[previous_sub['TARGET'] > 0.90]\n",
    "high_conf_repay = previous_sub[previous_sub['TARGET'] < 0.05]\n",
    "\n",
    "print(f\"High confidence defaults found: {len(high_conf_default)}\")\n",
    "print(f\"High confidence repayments found: {len(high_conf_repay)}\")\n",
    "\n",
    "# 3. Create \"Pseudo-Training\" Data\n",
    "# Assign labels: 1 for defaults, 0 for repayments\n",
    "test_defaults = test[test['SK_ID_CURR'].isin(high_conf_default['SK_ID_CURR'])].copy()\n",
    "test_defaults['TARGET'] = 1\n",
    "\n",
    "test_repayments = test[test['SK_ID_CURR'].isin(high_conf_repay['SK_ID_CURR'])].copy()\n",
    "test_repayments['TARGET'] = 0\n",
    "\n",
    "# Add to original training data\n",
    "augmented_train = pd.concat([train, test_defaults, test_repayments], sort=False)\n",
    "print(f\"Original Train shape: {train.shape}\")\n",
    "print(f\"Augmented Train shape: {augmented_train.shape}\")\n",
    "\n",
    "# 4. Feature Engineering (Standard \"Grandmaster\" Set)\n",
    "print(\"Engineering features on augmented data...\")\n",
    "# Fix anomalies\n",
    "augmented_train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "augmented_train = augmented_train[augmented_train['AMT_INCOME_TOTAL'] < 20000000]\n",
    "\n",
    "data = pd.concat([augmented_train, test], sort=False)\n",
    "\n",
    "# Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "\n",
    "# External Sources\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SCORE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SCORE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORE_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "\n",
    "# Encoding\n",
    "print(\"Encoding...\")\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "data.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "# Split\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 5. Training on Augmented Data\n",
    "print(\"Starting Pseudo-Label Training...\")\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "feature_columns = [c for c in train_df.columns if c != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # We use a slightly more aggressive learning rate since we have more data\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.015,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    sub_preds += model.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    print(f\"Fold {n_fold+1} Finished.\")\n",
    "\n",
    "# 6. Save\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "submission.to_csv('submission_pseudo_label.csv', index=False)\n",
    "print(\"Saved 'submission_pseudo_label.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "64600bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 13: PSEUDO-LABELING (FIXED) ---\n",
      "Loading data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "CRITICAL ERROR: Could not find 'submission_monster_ensemble.csv'.\nYou MUST run the previous 'Monster Ensemble' step successfully to generate this file first.\nPlease go back and run the previous code block.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[395], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully loaded \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# STOP HERE if file is missing\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRITICAL ERROR: Could not find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou MUST run the previous \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonster Ensemble\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m step successfully to generate this file first.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease go back and run the previous code block.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 3. Select High-Confidence Test Samples\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# We take rows where the model is >90% sure it's a default, or <5% sure (repayment)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m high_conf_default \u001b[38;5;241m=\u001b[39m previous_sub[previous_sub[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTARGET\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.90\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: CRITICAL ERROR: Could not find 'submission_monster_ensemble.csv'.\nYou MUST run the previous 'Monster Ensemble' step successfully to generate this file first.\nPlease go back and run the previous code block."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- STEP 13: PSEUDO-LABELING (FIXED) ---\")\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Load Previous Predictions (Safety Check)\n",
    "file_name = 'submission_monster_ensemble.csv'\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    previous_sub = pd.read_csv(file_name)\n",
    "    print(f\"Successfully loaded '{file_name}'.\")\n",
    "else:\n",
    "    # STOP HERE if file is missing\n",
    "    raise FileNotFoundError(f\"CRITICAL ERROR: Could not find '{file_name}'.\\n\"\n",
    "                            \"You MUST run the previous 'Monster Ensemble' step successfully to generate this file first.\\n\"\n",
    "                            \"Please go back and run the previous code block.\")\n",
    "\n",
    "# 3. Select High-Confidence Test Samples\n",
    "# We take rows where the model is >90% sure it's a default, or <5% sure (repayment)\n",
    "high_conf_default = previous_sub[previous_sub['TARGET'] > 0.90]\n",
    "high_conf_repay = previous_sub[previous_sub['TARGET'] < 0.05]\n",
    "\n",
    "print(f\"High confidence defaults found: {len(high_conf_default)}\")\n",
    "print(f\"High confidence repayments found: {len(high_conf_repay)}\")\n",
    "\n",
    "# 4. Create \"Pseudo-Training\" Data\n",
    "# Assign labels: 1 for defaults, 0 for repayments\n",
    "test_defaults = test[test['SK_ID_CURR'].isin(high_conf_default['SK_ID_CURR'])].copy()\n",
    "test_defaults['TARGET'] = 1\n",
    "\n",
    "test_repayments = test[test['SK_ID_CURR'].isin(high_conf_repay['SK_ID_CURR'])].copy()\n",
    "test_repayments['TARGET'] = 0\n",
    "\n",
    "# Add to original training data\n",
    "augmented_train = pd.concat([train, test_defaults, test_repayments], sort=False)\n",
    "print(f\"Original Train shape: {train.shape}\")\n",
    "print(f\"Augmented Train shape: {augmented_train.shape}\")\n",
    "\n",
    "# 5. Feature Engineering (Standard Set)\n",
    "print(\"Engineering features on augmented data...\")\n",
    "# Fix anomalies\n",
    "augmented_train['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "test['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "augmented_train = augmented_train[augmented_train['AMT_INCOME_TOTAL'] < 20000000]\n",
    "\n",
    "data = pd.concat([augmented_train, test], sort=False)\n",
    "\n",
    "# Ratios\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['GOODS_LOAN_RATIO'] = data['AMT_GOODS_PRICE'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "data['INCOME_CREDIT_PERC'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "data['ANNUITY_INCOME_PERC'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "\n",
    "# External Sources\n",
    "for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "data['EXT_SCORE_WEIGHTED'] = data.EXT_SOURCE_1 * 2 + data.EXT_SOURCE_2 * 3 + data.EXT_SOURCE_3 * 4\n",
    "data['EXT_SCORE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "data['EXT_SCORE_PROD'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "\n",
    "# Encoding\n",
    "print(\"Encoding...\")\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "data.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in data.columns]\n",
    "\n",
    "# Split\n",
    "train_df = data[data['TARGET'].notnull()]\n",
    "test_df = data[data['TARGET'].isnull()].drop('TARGET', axis=1)\n",
    "\n",
    "# 6. Training on Augmented Data\n",
    "print(\"Starting Pseudo-Label Training...\")\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "\n",
    "feature_columns = [c for c in train_df.columns if c != 'TARGET']\n",
    "\n",
    "for n_fold, (train_idx, val_idx) in enumerate(folds.split(train_df, train_df['TARGET'])):\n",
    "    X_train, y_train = train_df[feature_columns].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    X_val, y_val = train_df[feature_columns].iloc[val_idx], train_df['TARGET'].iloc[val_idx]\n",
    "    \n",
    "    # Aggressive learning rate for pseudo-labeling\n",
    "    model = lgb.LGBMClassifier(\n",
    "        n_estimators=3000,\n",
    "        learning_rate=0.015,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9,\n",
    "        subsample=0.8,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.04,\n",
    "        reg_lambda=0.07,\n",
    "        min_split_gain=0.02,\n",
    "        min_child_weight=39,\n",
    "        random_state=1001,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)], \n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(500)]\n",
    "    )\n",
    "    \n",
    "    sub_preds += model.predict_proba(test_df)[:, 1] / folds.get_n_splits()\n",
    "    print(f\"Fold {n_fold+1} Finished.\")\n",
    "\n",
    "# 7. Save\n",
    "submission = pd.DataFrame({\n",
    "    'SK_ID_CURR': test['SK_ID_CURR'],\n",
    "    'TARGET': sub_preds\n",
    "})\n",
    "submission.to_csv('submission_pseudo_label.csv', index=False)\n",
    "print(\"Saved 'submission_pseudo_label.csv'!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
